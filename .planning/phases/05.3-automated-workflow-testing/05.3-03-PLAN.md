---
phase: 05.3-automated-workflow-testing
plan: 03
type: execute
wave: 3
depends_on: ["05.3-02"]
files_modified:
  - src/executor/tests/executor.test.ts
  - src/index.ts
autonomous: true

must_haves:
  truths:
    - "Linear workflow pattern (Manual Trigger -> Set -> output) passes end-to-end test"
    - "Branching workflow pattern (IF with both true and false paths) passes end-to-end test"
    - "Error handling workflow pattern (error connection to handler) passes end-to-end test"
    - "Webhook trigger workflow passes end-to-end test via triggerWebhook()"
    - "All executor functions exported from SDK index"
  artifacts:
    - path: "src/executor/tests/executor.test.ts"
      provides: "Integration tests for executor module — 3 workflow patterns tested end-to-end"
      contains: "testWorkflow"
    - path: "src/index.ts"
      provides: "Exports for executor module"
      contains: "executor"
  key_links:
    - from: "src/executor/tests/executor.test.ts"
      to: "src/executor/test-harness.ts"
      via: "testWorkflow() with real workflow builders and scenarios"
      pattern: "testWorkflow"
    - from: "src/index.ts"
      to: "src/executor/"
      via: "re-export of executor types and functions"
      pattern: "executor"
---

<objective>
Write end-to-end integration tests for 3 workflow patterns using testWorkflow, add SDK exports, and verify the complete build-deploy-test-fix loop works.

Purpose: Prove the test harness works with real workflows against live n8n. Three patterns cover the success criteria: linear, branching, and error handling.

Output: Integration test file with 3 workflow patterns tested, updated index.ts exports.
</objective>

<execution_context>
@/Users/jurissleiners/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jurissleiners/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/05.3-automated-workflow-testing/05.3-01-SUMMARY.md
@.planning/phases/05.3-automated-workflow-testing/05.3-02-SUMMARY.md
@src/executor/types.ts
@src/executor/execute.ts
@src/executor/test-harness.ts
@src/compiler/tests/integration.test.ts
@src/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add executor exports to SDK index</name>
  <files>src/index.ts</files>
  <action>
Add executor exports to src/index.ts, following the existing pattern:

```typescript
// Executor (workflow testing)
export * from './executor/types.js';
export { executeWorkflow, getExecution, deleteWorkflow, triggerWebhook } from './executor/execute.js';
export { testWorkflow } from './executor/test-harness.js';
```

Place after the existing Deployer exports section.
  </action>
  <verify>`npx tsc --noEmit` passes.</verify>
  <done>All executor types and functions exported from SDK index.</done>
</task>

<task type="auto">
  <name>Task 2: Write end-to-end integration tests for 3 workflow patterns</name>
  <files>src/executor/tests/executor.test.ts</files>
  <action>
Create `src/executor/tests/executor.test.ts` with integration tests using the same n8n availability check pattern from `src/compiler/tests/integration.test.ts`.

Follow the exact same structure: `checkAvailability()` in `beforeAll`, skip gracefully if n8n unavailable.

**Test 1: Linear workflow (Manual Trigger -> Set -> verify output)**

```typescript
it('should test linear workflow end-to-end', async () => {
  if (!n8nAvailable) return;

  const wf = workflow('E2E Test — Linear');
  const trigger = wf.trigger('Manual Trigger', 'n8n-nodes-base.manualTrigger', {});
  const setNode = wf.node('Set Data', 'n8n-nodes-base.set', {
    mode: 'manual',
    duplicateItem: false,
    assignments: {
      assignments: [{
        id: crypto.randomUUID(),
        name: 'greeting',
        value: 'hello world',
        type: 'string',
      }]
    },
    includeOtherFields: false,
    options: {},
  });
  wf.connect(trigger, setNode);

  const report = await testWorkflow(wf, [{
    name: 'linear flow produces output',
    expectedStatus: 'success',
    expectedNodes: ['Set Data'],
  }]);

  expect(report.passed).toBe(1);
  expect(report.failed).toBe(0);
  expect(report.cleaned).toBe(true);
});
```

NOTE: The Set node parameters above are for Set v3 (typeVersion 3.4). If they differ based on Plan 01 research, adjust accordingly. The important thing is to use a simple Manual Trigger -> Set pattern that verifies execution completes successfully and the Set node appears in execution data.

**Test 2: Branching workflow (IF with both paths verified)**

```typescript
it('should test branching workflow end-to-end', async () => {
  if (!n8nAvailable) return;

  const wf = workflow('E2E Test — Branching');
  const trigger = wf.trigger('Manual Trigger', 'n8n-nodes-base.manualTrigger', {});
  const ifNode = wf.node('IF', 'n8n-nodes-base.if', {
    conditions: {
      options: { caseSensitive: true, leftValue: '' },
      conditions: [{
        id: crypto.randomUUID(),
        leftValue: '={{ 1 }}',
        rightValue: '={{ 1 }}',
        operator: { type: 'number', operation: 'equals' },
      }],
      combinator: 'and',
    },
    options: {},
  });
  const trueSet = wf.node('True Branch', 'n8n-nodes-base.set', {
    mode: 'manual',
    duplicateItem: false,
    assignments: {
      assignments: [{
        id: crypto.randomUUID(),
        name: 'branch',
        value: 'true',
        type: 'string',
      }]
    },
    includeOtherFields: false,
    options: {},
  });

  wf.connect(trigger, ifNode);
  wf.connect(ifNode, trueSet, 0);  // True output

  const report = await testWorkflow(wf, [{
    name: 'IF routes to true branch when condition matches',
    expectedStatus: 'success',
    expectedNodes: ['IF', 'True Branch'],
  }]);

  expect(report.passed).toBe(1);
  expect(report.failed).toBe(0);
  expect(report.cleaned).toBe(true);
});
```

NOTE: IF node v2 uses a different conditions structure than v1. The above uses v2 format. Adjust based on what the schema registry reports for IF typeVersion. The key goal: build a workflow where the IF condition evaluates to true, and verify the true branch node appears in execution data.

**Test 3: Error handling workflow (connect error path)**

```typescript
it('should test error handling workflow end-to-end', async () => {
  if (!n8nAvailable) return;

  // Use a Code node that throws an error to trigger the error path
  const wf = workflow('E2E Test — Error Handling');
  const trigger = wf.trigger('Manual Trigger', 'n8n-nodes-base.manualTrigger', {});
  const codeNode = wf.node('Failing Code', 'n8n-nodes-base.code', {
    jsCode: 'throw new Error("intentional test error");',
    mode: 'runOnceForAllItems',
  });
  const errorHandler = wf.node('Error Handler', 'n8n-nodes-base.set', {
    mode: 'manual',
    duplicateItem: false,
    assignments: {
      assignments: [{
        id: crypto.randomUUID(),
        name: 'caught',
        value: 'yes',
        type: 'string',
      }]
    },
    includeOtherFields: false,
    options: {},
  });

  wf.connect(trigger, codeNode);
  wf.connectError(codeNode, errorHandler);

  const report = await testWorkflow(wf, [{
    name: 'error connection routes to error handler',
    expectedStatus: 'success',  // Workflow succeeds overall because error is handled
    expectedNodes: ['Error Handler'],
  }]);

  expect(report.passed).toBe(1);
  expect(report.failed).toBe(0);
  expect(report.cleaned).toBe(true);
});
```

NOTE: The Code node (n8n-nodes-base.code) throws an error intentionally. With `continueOnFail` or error connection, this should route to the Error Handler node. If the Code node doesn't have the right params or error handling works differently, adjust. The key goal: verify that connectError() produces a workflow where errors flow to the handler node.

IMPORTANT: The node parameters above are APPROXIMATE. The executor must handle the real n8n execution API. If parameters need adjustment based on what Plan 01 and Plan 02 discovered, adjust them. Use the schema registry typeVersion patterns from Phase 5.2. The test names and patterns (linear, branching, error) must stay.

**Test 4: Webhook trigger workflow**

```typescript
it('should test webhook trigger workflow end-to-end', async () => {
  if (!n8nAvailable) return;

  const wf = workflow('E2E Test — Webhook');
  const webhook = wf.trigger('Webhook', 'n8n-nodes-base.webhook', {
    path: 'test-executor-' + Date.now(),
    httpMethod: 'POST',
    responseMode: 'lastNode',
    options: {},
  });
  const setNode = wf.node('Echo', 'n8n-nodes-base.set', {
    mode: 'manual',
    duplicateItem: false,
    assignments: {
      assignments: [{
        id: crypto.randomUUID(),
        name: 'received',
        value: '={{ $json.message }}',
        type: 'string',
      }]
    },
    includeOtherFields: false,
    options: {},
  });
  wf.connect(webhook, setNode);

  // Deploy and activate, then trigger via webhook endpoint
  const compiled = await compileWorkflow(wf);
  const deployResult = await deployWorkflow(wf, { activate: true });
  try {
    const webhookPath = 'test-executor-' + Date.now(); // match the path above
    const response = await triggerWebhook(
      compiled.nodes.find(n => n.name === 'Webhook')?.parameters?.path as string || webhookPath,
      { message: 'hello from test' }
    );
    expect(response).toBeDefined();
  } finally {
    await deleteWorkflow(deployResult.id);
  }
});
```

NOTE: This test verifies success criterion #1 — webhook trigger via `POST /webhook-test/{path}`. The path must match what the Webhook node is configured with. If Plan 01 research reveals webhook-test works differently (e.g., returns execution data inline vs needs polling), adjust accordingly. The key goal: prove triggerWebhook() can send a payload and get a response from an activated webhook workflow.

Also add a test for the testWorkflow feedback loop:

```typescript
it('should return detailed failure info when assertions fail', async () => {
  if (!n8nAvailable) return;

  const wf = workflow('E2E Test — Failure Feedback');
  const trigger = wf.trigger('Manual Trigger', 'n8n-nodes-base.manualTrigger', {});
  const setNode = wf.node('Set Data', 'n8n-nodes-base.set', { /* same as linear test */ });
  wf.connect(trigger, setNode);

  const report = await testWorkflow(wf, [{
    name: 'intentionally wrong assertion',
    expectedNodes: ['NonExistent Node'],  // This node doesn't exist in the workflow
  }]);

  expect(report.failed).toBe(1);
  expect(report.results[0].failures.length).toBeGreaterThan(0);
  expect(report.results[0].failures[0].type).toBe('missing_node');
  expect(report.results[0].actualOutput).toBeDefined();  // Full output available for diagnosis
  expect(report.cleaned).toBe(true);
});
```
  </action>
  <verify>
`npx vitest run` — all existing tests pass plus new executor tests pass (when n8n is available). When n8n is unavailable, tests skip gracefully.
  </verify>
  <done>5 integration tests pass: linear workflow, branching workflow, error handling workflow, webhook trigger, and failure feedback. All clean up after themselves. Test patterns cover success criteria #1 (manual + webhook trigger) and #7 (3+ workflow patterns tested end-to-end).</done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` — no type errors
2. `npx vitest run` — all tests pass (new + existing)
3. Executor functions exported from src/index.ts
4. 3 workflow patterns tested end-to-end: linear, branching, error handling
5. Failure feedback test proves Claude gets actionable diagnostics
6. All test workflows cleaned up (no leftover workflows in n8n)
7. Existing 80 tests still pass
</verification>

<success_criteria>
- testWorkflow works end-to-end with real n8n for 3+ workflow patterns
- Linear: Manual Trigger -> Set -> verify execution succeeds and Set node ran
- Branching: IF with condition -> true path verified
- Error: Code throws -> error connection -> Error Handler verified
- Webhook: Webhook trigger -> Set -> verify triggerWebhook() sends payload and gets response
- Failure feedback: wrong assertions produce TestFailure with type, message, expected, actual
- All executor types and functions exported from SDK index
- Zero regressions in existing test suite
</success_criteria>

<output>
After completion, create `.planning/phases/05.3-automated-workflow-testing/05.3-03-SUMMARY.md`
</output>
